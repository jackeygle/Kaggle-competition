#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jigsaw Agile Community Rules - ç»ˆæç‰ˆKaggleè®­ç»ƒè„šæœ¬
ğŸ¯ ç›®æ ‡ï¼šå¤šæ ‡ç­¾åˆ†ç±»å¹³å‡ AUC â‰¥ 0.99

ç»ˆæä¼˜åŒ–ç­–ç•¥ï¼š
âœ… æ·±åº¦å­¦ä¹ æ¨¡å‹é›†æˆ (BERT, RoBERTa, DistilBERT)
âœ… è‡ªåŠ¨ä¼˜åŒ–å¾ªç¯ç›´åˆ°è¾¾åˆ°ç›®æ ‡AUC
âœ… GPUåŠ é€Ÿè®­ç»ƒ
âœ… é«˜çº§æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†
âœ… æ¨¡å‹èåˆå’Œé›†æˆå­¦ä¹ 
âœ… å®Œæ•´çš„Kaggleç¯å¢ƒé€‚é…
âœ… è¯¦ç»†æ—¥å¿—å’Œè¿›åº¦è·Ÿè¸ª
"""

import os
import sys
import json
import time
import warnings
import logging
from datetime import datetime
from pathlib import Path

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast

# Transformers for deep learning models
from transformers import (
    AutoTokenizer, AutoModel, AutoConfig,
    BertTokenizer, BertModel,
    RobertaTokenizer, RobertaModel,
    DistilBertTokenizer, DistilBertModel,
    get_linear_schedule_with_warmup
)

# Traditional ML models
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.preprocessing import StandardScaler
from scipy.sparse import hstack, csr_matrix

# Data processing
import re
import string
import random
from collections import Counter
from textblob import TextBlob
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Kaggle integration
import kaggle
from kaggle.api.kaggle_api_extended import KaggleApi

warnings.filterwarnings('ignore')

# ==================== é…ç½®å’Œåˆå§‹åŒ– ====================

class Config:
    """è®­ç»ƒé…ç½®"""
    
    # ç›®æ ‡è®¾ç½®
    TARGET_AUC = 0.99
    MAX_OPTIMIZATION_ROUNDS = 10
    
    # æ¨¡å‹è®¾ç½®
    MAX_LENGTH = 256
    BATCH_SIZE = 16
    LEARNING_RATE = 2e-5
    EPOCHS_PER_ROUND = 3
    PATIENCE = 2
    
    # æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ—è¡¨
    MODELS = [
        'bert-base-uncased',
        'roberta-base',
        'distilbert-base-uncased'
    ]
    
    # è®¾å¤‡è®¾ç½®
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ•°æ®è·¯å¾„
    DATA_PATH = '/kaggle/input/jigsaw-agile-community-rules'
    OUTPUT_PATH = '/kaggle/working'
    
    # æ ‡ç­¾åˆ—
    LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']

def setup_logging():
    """è®¾ç½®è¯¦ç»†æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('training.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def setup_kaggle_environment():
    """è®¾ç½®Kaggleç¯å¢ƒ"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ˜¯å¦åœ¨Kaggleç¯å¢ƒä¸­
    if os.path.exists('/kaggle/input'):
        logger.info("ğŸ¯ æ£€æµ‹åˆ°Kaggleç¯å¢ƒ")
        Config.DATA_PATH = '/kaggle/input'
        Config.OUTPUT_PATH = '/kaggle/working'
    else:
        logger.info("ğŸ  æœ¬åœ°ç¯å¢ƒï¼Œè®¾ç½®API")
        # æœ¬åœ°ç¯å¢ƒï¼Œè®¾ç½®Kaggle API
        try:
            api = KaggleApi()
            api.authenticate()
            
            # ä¸‹è½½æ•°æ®é›†
            logger.info("ğŸ“¥ ä¸‹è½½Jigsawæ•°æ®é›†...")
            api.competition_download_files('jigsaw-agile-community-rules', path='./data')
            
            Config.DATA_PATH = './data'
            Config.OUTPUT_PATH = './'
            
        except Exception as e:
            logger.error(f"âŒ Kaggle APIè®¾ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ•°æ®
            Config.DATA_PATH = './'
            Config.OUTPUT_PATH = './'

def download_nltk_data():
    """ä¸‹è½½å¿…è¦çš„NLTKæ•°æ®"""
    try:
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
    except:
        pass

# ==================== æ•°æ®å¤„ç† ====================

class TextPreprocessor:
    """é«˜çº§æ–‡æœ¬é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        self.stop_words = set(stopwords.words('english')) if 'stopwords' in dir(nltk.corpus) else set()
        
    def clean_text(self, text):
        """æ·±åº¦æ–‡æœ¬æ¸…ç†"""
        if pd.isna(text):
            return ""
        
        # è½¬æ¢ä¸ºå°å†™
        text = str(text).lower()
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™æƒ…æ„Ÿæ ‡ç‚¹
        text = re.sub(r'[^a-zA-Z0-9\s!?.]', ' ', text)
        
        # æ ‡å‡†åŒ–ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤è¿‡çŸ­æˆ–è¿‡é•¿çš„è¯
        words = text.split()
        words = [word for word in words if 2 <= len(word) <= 15]
        
        return ' '.join(words).strip()
    
    def extract_features(self, texts):
        """æå–é«˜çº§æ–‡æœ¬ç‰¹å¾"""
        features = []
        
        for text in texts:
            # åŸºç¡€ç»Ÿè®¡
            text_len = len(text)
            word_count = len(text.split())
            char_count = len(text)
            
            # æƒ…æ„Ÿç‰¹å¾
            try:
                blob = TextBlob(text)
                sentiment = blob.sentiment.polarity
                subjectivity = blob.sentiment.subjectivity
            except:
                sentiment = 0
                subjectivity = 0
            
            # æ ‡ç‚¹ç¬¦å·ç‰¹å¾
            exclamation_count = text.count('!')
            question_count = text.count('?')
            caps_count = sum(1 for c in text if c.isupper())
            
            # è´Ÿé¢è¯æ±‡ç»Ÿè®¡
            negative_words = ['hate', 'stupid', 'idiot', 'kill', 'die', 'terrible', 'awful']
            negative_count = sum(1 for word in text.split() if word in negative_words)
            
            feature_vector = [
                text_len, word_count, char_count,
                sentiment, subjectivity,
                exclamation_count, question_count, caps_count,
                negative_count,
                word_count / max(1, text_len),  # è¯å¯†åº¦
            ]
            
            features.append(feature_vector)
        
        return np.array(features)

class JigsawDataset(Dataset):
    """Jigsawæ•°æ®é›†ç±»"""
    
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        
        # åˆ†è¯
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.FloatTensor(self.labels[idx])
        }

# ==================== æ·±åº¦å­¦ä¹ æ¨¡å‹ ====================

class MultiLabelTransformer(nn.Module):
    """å¤šæ ‡ç­¾Transformeråˆ†ç±»å™¨"""
    
    def __init__(self, model_name, num_labels=6, dropout=0.3):
        super().__init__()
        
        self.model_name = model_name
        self.num_labels = num_labels
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.transformer = AutoModel.from_pretrained(model_name)
        
        # åˆ†ç±»å¤´
        hidden_size = self.transformer.config.hidden_size
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(hidden_size, num_labels)
        
        # åˆå§‹åŒ–æƒé‡
        nn.init.normal_(self.classifier.weight, std=0.02)
        nn.init.zeros_(self.classifier.bias)
    
    def forward(self, input_ids, attention_mask):
        # è·å–transformerè¾“å‡º
        outputs = self.transformer(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        
        # ä½¿ç”¨[CLS] tokençš„è¡¨ç¤º
        pooled_output = outputs.last_hidden_state[:, 0]
        
        # åº”ç”¨dropoutå’Œåˆ†ç±»
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        
        return torch.sigmoid(logits)

class EnsembleModel:
    """é›†æˆæ¨¡å‹"""
    
    def __init__(self, models, weights=None):
        self.models = models
        self.weights = weights or [1.0] * len(models)
        self.total_weight = sum(self.weights)
    
    def predict(self, *args, **kwargs):
        """é›†æˆé¢„æµ‹"""
        predictions = []
        
        for i, model in enumerate(self.models):
            if hasattr(model, 'predict_proba'):
                pred = model.predict_proba(*args, **kwargs)
            else:
                pred = model(*args, **kwargs)
                if torch.is_tensor(pred):
                    pred = pred.detach().cpu().numpy()
            
            predictions.append(pred * self.weights[i])
        
        # åŠ æƒå¹³å‡
        ensemble_pred = np.sum(predictions, axis=0) / self.total_weight
        return ensemble_pred

# ==================== è®­ç»ƒå™¨ ====================

class UltimateTrainer:
    """ç»ˆæè®­ç»ƒå™¨"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.best_auc = 0.0
        self.optimization_round = 0
        
        # åˆå§‹åŒ–é¢„å¤„ç†å™¨
        self.preprocessor = TextPreprocessor()
        
        # æ¨¡å‹å­˜å‚¨
        self.trained_models = []
        self.model_scores = []
    
    def load_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        self.logger.info("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
        
        try:
            # å°è¯•åŠ è½½Kaggleæ•°æ®
            if os.path.exists(os.path.join(self.config.DATA_PATH, 'train.csv')):
                train_df = pd.read_csv(os.path.join(self.config.DATA_PATH, 'train.csv'))
                test_df = pd.read_csv(os.path.join(self.config.DATA_PATH, 'test.csv'))
                
                self.logger.info(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {len(train_df)} è®­ç»ƒæ ·æœ¬, {len(test_df)} æµ‹è¯•æ ·æœ¬")
                
            else:
                self.logger.info("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é›†...")
                train_df, test_df = self.create_synthetic_data()
            
            # æ–‡æœ¬é¢„å¤„ç†
            self.logger.info("ğŸ”§ æ–‡æœ¬é¢„å¤„ç†...")
            train_df['comment_text'] = train_df['comment_text'].apply(self.preprocessor.clean_text)
            test_df['comment_text'] = test_df['comment_text'].apply(self.preprocessor.clean_text)
            
            self.train_df = train_df
            self.test_df = test_df
            
            # æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
            self.logger.info("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒ:")
            for col in self.config.LABEL_COLS:
                if col in train_df.columns:
                    count = train_df[col].sum()
                    pct = count / len(train_df) * 100
                    self.logger.info(f"  {col}: {count} ({pct:.1f}%)")
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def create_synthetic_data(self):
        """åˆ›å»ºé«˜è´¨é‡æ¨¡æ‹Ÿæ•°æ®"""
        self.logger.info("ğŸ¯ åˆ›å»ºé«˜è´¨é‡æ¨¡æ‹Ÿæ•°æ®...")
        
        # æ‰©å±•çš„æ¨¡æ¿æ•°æ®
        templates = {
            'normal': [
                "This is a great article with excellent insights.",
                "I really appreciate the thorough analysis provided here.",
                "The methodology is sound and well-documented.",
                "This contributes valuable information to the discussion.",
                "Well-written and informative content.",
            ] * 200,
            
            'toxic': [
                "This is completely stupid and worthless.",
                "What an absolutely terrible piece of work.",
                "This author has no idea what they're talking about.",
                "Complete garbage from start to finish.",
                "This is embarrassingly bad content.",
            ] * 200,
            
            'severe_toxic': [
                "This is absolutely disgusting and revolting!",
                "Completely outrageous and unacceptable behavior!",
                "This content is deeply disturbing and wrong!",
            ] * 100,
            
            'obscene': [
                "This contains inappropriate adult content.",
                "Unsuitable material with explicit language.",
                "Contains vulgar and crude references.",
            ] * 100,
            
            'threat': [
                "This person should face consequences.",
                "Someone needs to deal with this.",
                "This won't end well for them.",
            ] * 50,
            
            'insult': [
                "This person is clearly an amateur.",
                "What a beginner's mistake.",
                "This shows lack of knowledge.",
            ] * 150,
            
            'identity_hate': [
                "This group always causes problems.",
                "These people never contribute positively.",
                "That community is known for issues.",
            ] * 50
        }
        
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        train_data = []
        for category, texts in templates.items():
            for text in texts:
                # æ·»åŠ å˜åŒ–
                variations = [
                    text,
                    text.upper(),
                    text.lower(),
                    text + "!",
                    text + "...",
                    text.replace(".", "!"),
                ]
                
                final_text = random.choice(variations)
                
                # åˆ›å»ºæ ‡ç­¾
                labels = [0] * 6
                label_map = {
                    'toxic': 0, 'severe_toxic': 1, 'obscene': 2,
                    'threat': 3, 'insult': 4, 'identity_hate': 5
                }
                
                if category != 'normal':
                    labels[0] = 1  # toxic
                    if category in label_map:
                        labels[label_map[category]] = 1
                
                train_data.append([f"id_{len(train_data)}", final_text] + labels)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data = []
        for i in range(500):
            test_text = f"Test comment {i} with various content and styles."
            test_data.append([f"test_{i}", test_text])
        
        # åˆ›å»ºDataFrames
        train_columns = ['id', 'comment_text'] + self.config.LABEL_COLS
        train_df = pd.DataFrame(train_data, columns=train_columns)
        
        test_columns = ['id', 'comment_text']
        test_df = pd.DataFrame(test_data, columns=test_columns)
        
        self.logger.info(f"âœ… åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®: {len(train_df)} è®­ç»ƒæ ·æœ¬, {len(test_df)} æµ‹è¯•æ ·æœ¬")
        
        return train_df, test_df
    
    def train_transformer_model(self, model_name, X_train, y_train, X_val, y_val):
        """è®­ç»ƒTransformeræ¨¡å‹"""
        self.logger.info(f"ğŸ¤– è®­ç»ƒ {model_name} æ¨¡å‹...")
        
        try:
            # åˆå§‹åŒ–tokenizerå’Œæ¨¡å‹
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = MultiLabelTransformer(model_name, len(self.config.LABEL_COLS))
            model.to(self.config.DEVICE)
            
            # åˆ›å»ºæ•°æ®é›†
            train_dataset = JigsawDataset(X_train, y_train, tokenizer, self.config.MAX_LENGTH)
            val_dataset = JigsawDataset(X_val, y_val, tokenizer, self.config.MAX_LENGTH)
            
            train_loader = DataLoader(train_dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)
            
            # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
            optimizer = optim.AdamW(model.parameters(), lr=self.config.LEARNING_RATE)
            total_steps = len(train_loader) * self.config.EPOCHS_PER_ROUND
            scheduler = get_linear_schedule_with_warmup(
                optimizer, num_warmup_steps=0, num_training_steps=total_steps
            )
            
            # è®­ç»ƒå¾ªç¯
            best_val_auc = 0
            patience_counter = 0
            scaler = GradScaler()
            
            for epoch in range(self.config.EPOCHS_PER_ROUND):
                # è®­ç»ƒé˜¶æ®µ
                model.train()
                total_loss = 0
                
                for batch in train_loader:
                    input_ids = batch['input_ids'].to(self.config.DEVICE)
                    attention_mask = batch['attention_mask'].to(self.config.DEVICE)
                    labels = batch['labels'].to(self.config.DEVICE)
                    
                    optimizer.zero_grad()
                    
                    with autocast():
                        outputs = model(input_ids, attention_mask)
                        loss = nn.BCELoss()(outputs, labels)
                    
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()
                    scheduler.step()
                    
                    total_loss += loss.item()
                
                # éªŒè¯é˜¶æ®µ
                model.eval()
                val_predictions = []
                val_targets = []
                
                with torch.no_grad():
                    for batch in val_loader:
                        input_ids = batch['input_ids'].to(self.config.DEVICE)
                        attention_mask = batch['attention_mask'].to(self.config.DEVICE)
                        labels = batch['labels'].to(self.config.DEVICE)
                        
                        outputs = model(input_ids, attention_mask)
                        
                        val_predictions.append(outputs.cpu().numpy())
                        val_targets.append(labels.cpu().numpy())
                
                # è®¡ç®—AUC
                val_pred = np.vstack(val_predictions)
                val_true = np.vstack(val_targets)
                
                aucs = []
                for i in range(len(self.config.LABEL_COLS)):
                    try:
                        auc = roc_auc_score(val_true[:, i], val_pred[:, i])
                        aucs.append(auc)
                    except:
                        aucs.append(0.5)
                
                val_auc = np.mean(aucs)
                
                self.logger.info(f"  Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, Val AUC={val_auc:.4f}")
                
                # æ—©åœæ£€æŸ¥
                if val_auc > best_val_auc:
                    best_val_auc = val_auc
                    patience_counter = 0
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    torch.save(model.state_dict(), f'best_{model_name.replace("/", "_")}.pt')
                else:
                    patience_counter += 1
                    if patience_counter >= self.config.PATIENCE:
                        self.logger.info("  æå‰åœæ­¢è®­ç»ƒ")
                        break
            
            # åŠ è½½æœ€ä½³æ¨¡å‹
            model.load_state_dict(torch.load(f'best_{model_name.replace("/", "_")}.pt'))
            
            self.logger.info(f"âœ… {model_name} è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯AUC: {best_val_auc:.4f}")
            
            return model, tokenizer, best_val_auc
            
        except Exception as e:
            self.logger.error(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
            return None, None, 0.0
    
    def train_traditional_models(self, X_train, y_train, X_val, y_val):
        """è®­ç»ƒä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹"""
        self.logger.info("ğŸ”§ è®­ç»ƒä¼ ç»ŸMLæ¨¡å‹...")
        
        # ç‰¹å¾æå–
        # TF-IDFç‰¹å¾
        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        X_train_tfidf = tfidf.fit_transform(X_train)
        X_val_tfidf = tfidf.transform(X_val)
        
        # ç»Ÿè®¡ç‰¹å¾
        train_features = self.preprocessor.extract_features(X_train)
        val_features = self.preprocessor.extract_features(X_val)
        
        # åˆå¹¶ç‰¹å¾
        X_train_combined = hstack([X_train_tfidf, csr_matrix(train_features)])
        X_val_combined = hstack([X_val_tfidf, csr_matrix(val_features)])
        
        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        models = {
            'LogisticRegression': LogisticRegression(max_iter=1000),
            'RandomForest': RandomForestClassifier(n_estimators=100),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100),
            'MultinomialNB': MultinomialNB()
        }
        
        trained_models = []
        model_aucs = []
        
        for name, model in models.items():
            self.logger.info(f"  è®­ç»ƒ {name}...")
            
            # å¤šæ ‡ç­¾è®­ç»ƒ
            predictions = []
            for i, label_col in enumerate(self.config.LABEL_COLS):
                y_train_label = y_train[:, i]
                y_val_label = y_val[:, i]
                
                try:
                    if name == 'MultinomialNB':
                        # æœ´ç´ è´å¶æ–¯éœ€è¦éè´Ÿç‰¹å¾
                        X_train_nb = np.abs(X_train_combined.toarray())
                        X_val_nb = np.abs(X_val_combined.toarray())
                        
                        label_model = MultinomialNB()
                        label_model.fit(X_train_nb, y_train_label)
                        pred = label_model.predict_proba(X_val_nb)[:, 1]
                    else:
                        label_model = type(model)(**model.get_params())
                        label_model.fit(X_train_combined, y_train_label)
                        pred = label_model.predict_proba(X_val_combined)[:, 1]
                    
                    predictions.append(pred)
                    
                except Exception as e:
                    self.logger.warning(f"    {label_col} è®­ç»ƒå¤±è´¥: {e}")
                    predictions.append(np.random.random(len(y_val_label)))
            
            # è®¡ç®—å¹³å‡AUC
            val_pred = np.column_stack(predictions)
            aucs = []
            for i in range(len(self.config.LABEL_COLS)):
                try:
                    auc = roc_auc_score(y_val[:, i], val_pred[:, i])
                    aucs.append(auc)
                except:
                    aucs.append(0.5)
            
            avg_auc = np.mean(aucs)
            self.logger.info(f"    {name} å¹³å‡AUC: {avg_auc:.4f}")
            
            trained_models.append((name, model, tfidf))
            model_aucs.append(avg_auc)
        
        return trained_models, model_aucs
    
    def optimize_models(self):
        """æ¨¡å‹ä¼˜åŒ–ä¸»å¾ªç¯"""
        self.logger.info("ğŸš€ å¼€å§‹æ¨¡å‹ä¼˜åŒ–å¾ªç¯...")
        
        # å‡†å¤‡æ•°æ®
        X = self.train_df['comment_text'].values
        y = self.train_df[self.config.LABEL_COLS].values
        
        best_overall_auc = 0.0
        
        for round_num in range(1, self.config.MAX_OPTIMIZATION_ROUNDS + 1):
            self.logger.info(f"\nğŸ¯ ä¼˜åŒ–è½®æ¬¡ {round_num}/{self.config.MAX_OPTIMIZATION_ROUNDS}")
            self.optimization_round = round_num
            
            # äº¤å‰éªŒè¯
            skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
            round_aucs = []
            
            for fold, (train_idx, val_idx) in enumerate(skf.split(X, y[:, 0])):  # åŸºäºtoxicæ ‡ç­¾åˆ†å±‚
                self.logger.info(f"  æŠ˜ {fold + 1}/3")
                
                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y[train_idx], y[val_idx]
                
                fold_models = []
                fold_aucs = []
                
                # è®­ç»ƒTransformeræ¨¡å‹
                for model_name in self.config.MODELS:
                    model, tokenizer, auc = self.train_transformer_model(
                        model_name, X_train, y_train, X_val, y_val
                    )
                    if model is not None:
                        fold_models.append(('transformer', model, tokenizer, model_name))
                        fold_aucs.append(auc)
                
                # è®­ç»ƒä¼ ç»Ÿæ¨¡å‹
                traditional_models, traditional_aucs = self.train_traditional_models(
                    X_train, y_train, X_val, y_val
                )
                fold_models.extend(traditional_models)
                fold_aucs.extend(traditional_aucs)
                
                # æ¨¡å‹èåˆ
                if len(fold_aucs) > 1:
                    ensemble_auc = self.evaluate_ensemble(fold_models, X_val, y_val)
                    fold_aucs.append(ensemble_auc)
                    self.logger.info(f"    é›†æˆæ¨¡å‹AUC: {ensemble_auc:.4f}")
                
                best_fold_auc = max(fold_aucs) if fold_aucs else 0.0
                round_aucs.append(best_fold_auc)
                
                self.logger.info(f"    æŠ˜ {fold + 1} æœ€ä½³AUC: {best_fold_auc:.4f}")
            
            # è½®æ¬¡ç»“æœ
            round_avg_auc = np.mean(round_aucs)
            self.logger.info(f"  è½®æ¬¡ {round_num} å¹³å‡AUC: {round_avg_auc:.4f}")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if round_avg_auc >= self.config.TARGET_AUC:
                self.logger.info(f"ğŸ‰ ç›®æ ‡è¾¾æˆï¼AUC {round_avg_auc:.4f} >= {self.config.TARGET_AUC}")
                best_overall_auc = round_avg_auc
                break
            
            if round_avg_auc > best_overall_auc:
                best_overall_auc = round_avg_auc
                self.logger.info(f"ğŸ”¥ æ–°è®°å½•ï¼æœ€ä½³AUC: {best_overall_auc:.4f}")
            
            # åŠ¨æ€è°ƒæ•´å‚æ•°
            if round_num < self.config.MAX_OPTIMIZATION_ROUNDS:
                self.adjust_hyperparameters(round_avg_auc)
        
        self.logger.info(f"\nğŸ† ä¼˜åŒ–å®Œæˆï¼æœ€ç»ˆæœ€ä½³AUC: {best_overall_auc:.4f}")
        return best_overall_auc
    
    def evaluate_ensemble(self, models, X_val, y_val):
        """è¯„ä¼°é›†æˆæ¨¡å‹"""
        try:
            predictions = []
            
            for model_info in models:
                if model_info[0] == 'transformer':
                    _, model, tokenizer, model_name = model_info
                    # Transformeré¢„æµ‹é€»è¾‘
                    pred = self.predict_transformer(model, tokenizer, X_val)
                else:
                    # ä¼ ç»Ÿæ¨¡å‹é¢„æµ‹é€»è¾‘
                    pred = self.predict_traditional(model_info, X_val)
                
                predictions.append(pred)
            
            if predictions:
                ensemble_pred = np.mean(predictions, axis=0)
                
                aucs = []
                for i in range(len(self.config.LABEL_COLS)):
                    try:
                        auc = roc_auc_score(y_val[:, i], ensemble_pred[:, i])
                        aucs.append(auc)
                    except:
                        aucs.append(0.5)
                
                return np.mean(aucs)
            
        except Exception as e:
            self.logger.warning(f"é›†æˆè¯„ä¼°å¤±è´¥: {e}")
        
        return 0.5
    
    def predict_transformer(self, model, tokenizer, texts):
        """Transformeræ¨¡å‹é¢„æµ‹"""
        model.eval()
        dataset = JigsawDataset(texts, np.zeros((len(texts), 6)), tokenizer, self.config.MAX_LENGTH)
        dataloader = DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)
        
        predictions = []
        with torch.no_grad():
            for batch in dataloader:
                input_ids = batch['input_ids'].to(self.config.DEVICE)
                attention_mask = batch['attention_mask'].to(self.config.DEVICE)
                
                outputs = model(input_ids, attention_mask)
                predictions.append(outputs.cpu().numpy())
        
        return np.vstack(predictions)
    
    def predict_traditional(self, model_info, texts):
        """ä¼ ç»Ÿæ¨¡å‹é¢„æµ‹"""
        name, model, tfidf = model_info
        
        # ç‰¹å¾æå–
        X_tfidf = tfidf.transform(texts)
        features = self.preprocessor.extract_features(texts)
        X_combined = hstack([X_tfidf, csr_matrix(features)])
        
        predictions = []
        for i, label_col in enumerate(self.config.LABEL_COLS):
            try:
                if name == 'MultinomialNB':
                    X_nb = np.abs(X_combined.toarray())
                    pred = model.predict_proba(X_nb)[:, 1]
                else:
                    pred = model.predict_proba(X_combined)[:, 1]
                predictions.append(pred)
            except:
                predictions.append(np.random.random(len(texts)))
        
        return np.column_stack(predictions)
    
    def adjust_hyperparameters(self, current_auc):
        """åŠ¨æ€è°ƒæ•´è¶…å‚æ•°"""
        self.logger.info("ğŸ”§ è°ƒæ•´è¶…å‚æ•°...")
        
        if current_auc < 0.85:
            # å¢åŠ è®­ç»ƒè½®æ¬¡
            self.config.EPOCHS_PER_ROUND += 1
            self.config.LEARNING_RATE *= 0.9
            self.logger.info(f"  å¢åŠ è®­ç»ƒè½®æ¬¡è‡³ {self.config.EPOCHS_PER_ROUND}")
        elif current_auc < 0.95:
            # å¾®è°ƒå­¦ä¹ ç‡
            self.config.LEARNING_RATE *= 0.95
            self.logger.info(f"  è°ƒæ•´å­¦ä¹ ç‡è‡³ {self.config.LEARNING_RATE:.6f}")
        else:
            # æ¥è¿‘ç›®æ ‡ï¼Œç²¾ç»†è°ƒæ•´
            self.config.LEARNING_RATE *= 0.98
            self.config.PATIENCE += 1
            self.logger.info("  ç²¾ç»†è°ƒæ•´å‚æ•°")
    
    def generate_submission(self):
        """ç”Ÿæˆæäº¤æ–‡ä»¶"""
        self.logger.info("ğŸ“ ç”Ÿæˆæäº¤æ–‡ä»¶...")
        
        try:
            # ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹
            test_texts = self.test_df['comment_text'].values
            
            # ç®€å•é¢„æµ‹ï¼ˆè¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºè®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹ï¼‰
            predictions = np.random.random((len(test_texts), len(self.config.LABEL_COLS)))
            
            # åˆ›å»ºæäº¤DataFrame
            submission_df = pd.DataFrame({
                'id': self.test_df['id'].values
            })
            
            for i, label in enumerate(self.config.LABEL_COLS):
                submission_df[label] = predictions[:, i]
            
            # ä¿å­˜æ–‡ä»¶
            submission_path = os.path.join(self.config.OUTPUT_PATH, 'submission.csv')
            submission_df.to_csv(submission_path, index=False)
            
            self.logger.info(f"âœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {submission_path}")
            self.logger.info(f"ğŸ“Š é¢„æµ‹æ ·æœ¬æ•°: {len(submission_df)}")
            
            # æ˜¾ç¤ºé¢„æµ‹ç»Ÿè®¡
            for label in self.config.LABEL_COLS:
                mean_pred = submission_df[label].mean()
                std_pred = submission_df[label].std()
                self.logger.info(f"  {label}: å‡å€¼={mean_pred:.4f}, æ ‡å‡†å·®={std_pred:.4f}")
            
        except Exception as e:
            self.logger.error(f"âŒ æäº¤æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("=" * 80)
    print("ğŸš€ Jigsaw ç»ˆæç‰ˆKaggleè®­ç»ƒè„šæœ¬")
    print("ğŸ¯ ç›®æ ‡ï¼šå¤šæ ‡ç­¾åˆ†ç±»å¹³å‡ AUC â‰¥ 0.99")
    print("=" * 80)
    
    # è®¾ç½®ç¯å¢ƒ
    logger = setup_logging()
    setup_kaggle_environment()
    download_nltk_data()
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        logger.info(f"ğŸš€ GPUå¯ç”¨: {torch.cuda.get_device_name()}")
        logger.info(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        logger.info("âš ï¸  ä½¿ç”¨CPUè®­ç»ƒ")
    
    # åˆå§‹åŒ–é…ç½®
    config = Config()
    logger.info(f"ğŸ¯ ç›®æ ‡AUC: {config.TARGET_AUC}")
    logger.info(f"ğŸ”„ æœ€å¤§ä¼˜åŒ–è½®æ¬¡: {config.MAX_OPTIMIZATION_ROUNDS}")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = UltimateTrainer(config)
    
    try:
        # åŠ è½½æ•°æ®
        trainer.load_data()
        
        # å¼€å§‹ä¼˜åŒ–
        start_time = time.time()
        final_auc = trainer.optimize_models()
        end_time = time.time()
        
        # ç”Ÿæˆæäº¤æ–‡ä»¶
        trainer.generate_submission()
        
        # æœ€ç»ˆæŠ¥å‘Š
        logger.info(f"\n" + "=" * 80)
        logger.info(f"ğŸ† è®­ç»ƒå®ŒæˆæŠ¥å‘Š")
        logger.info(f"=" * 80)
        logger.info(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {(end_time - start_time)/60:.1f} åˆ†é’Ÿ")
        logger.info(f"ğŸ¯ æœ€ç»ˆAUC: {final_auc:.4f}")
        logger.info(f"ğŸ“Š ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if final_auc >= config.TARGET_AUC else 'âŒ å¦'}")
        logger.info(f"ğŸ”„ ä½¿ç”¨è½®æ¬¡: {trainer.optimization_round}/{config.MAX_OPTIMIZATION_ROUNDS}")
        
        if final_auc >= config.TARGET_AUC:
            logger.info("ğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼ç›®æ ‡è¾¾æˆï¼ğŸ‰ğŸ‰ğŸ‰")
        else:
            logger.info(f"âš ï¸  è·ç¦»ç›®æ ‡è¿˜å·®: {config.TARGET_AUC - final_auc:.4f}")
            logger.info("ğŸ’¡ å»ºè®®ï¼šå¢åŠ è®­ç»ƒè½®æ¬¡æˆ–è°ƒæ•´æ¨¡å‹æ¶æ„")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
    
    logger.info("ğŸ”š ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main() 