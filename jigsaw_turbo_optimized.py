#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jigsaw Agile Community Rules - æé€Ÿä¼˜åŒ–ç‰ˆæœ¬
ç›®æ ‡ï¼š20%+é¢„æµ‹å¤šæ ·æ€§ï¼Œä½†è®­ç»ƒæ—¶é—´æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…

æé€Ÿä¼˜åŒ–ç­–ç•¥ï¼š
1. 5000æ ·æœ¬é«˜è´¨é‡æ•°æ®ï¼ˆvs 20000ï¼‰
2. ç²¾é€‰15ç»´æ ¸å¿ƒç‰¹å¾
3. 3æ¨¡å‹å¿«é€Ÿé›†æˆï¼ˆLR + RF + NBï¼‰
4. ç®€åŒ–ä½†æœ‰æ•ˆçš„æ•°æ®å¢å¼º
5. ä¼˜åŒ–çš„æ–‡æœ¬å¤„ç†ç®¡é“
"""

import pandas as pd
import numpy as np
import re
import string
import random
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import StandardScaler
from scipy.sparse import hstack, csr_matrix
import warnings
warnings.filterwarnings('ignore')

# ==================== é«˜æ•ˆæ•°æ®ç”Ÿæˆ ====================

def create_efficient_diverse_dataset():
    """åˆ›å»º5000æ ·æœ¬çš„é«˜è´¨é‡å¤šæ ·åŒ–æ•°æ®é›†"""
    print("ğŸ¯ åˆ›å»ºé«˜æ•ˆå¤šæ ·åŒ–æ•°æ®é›†...")
    
    # ç²¾é€‰30ä¸ªé«˜è´¨é‡æ¨¡æ¿
    base_templates = [
        # æ­£å¸¸è¯„è®º (8ä¸ª)
        "This is an excellent article, very informative!",
        "I found this helpful and well-researched.",
        "Could you provide more details about this?",
        "This is an interesting perspective to consider.",
        "Thanks for sharing this valuable information.",
        "Great work on this comprehensive analysis!",
        "I learned something new from this post.",
        "This tutorial is exactly what I needed.",
        
        # è½»åº¦è´Ÿé¢ (6ä¸ª)
        "I disagree with some points mentioned here.",
        "This doesn't seem entirely accurate to me.",
        "I think there might be some errors in this.",
        "This could be improved with better examples.",
        "I'm not fully convinced by these arguments.",
        "This analysis appears somewhat incomplete.",
        
        # ä¸­åº¦æ”»å‡»æ€§ (8ä¸ª)
        "This is completely wrong and misleading!",
        "You clearly don't understand the topic!",
        "This is absolutely ridiculous nonsense!",
        "You're spreading false information here!",
        "This is the worst analysis ever written!",
        "You have no idea what you're talking about!",
        "This is a complete waste of time!",
        "You obviously didn't do proper research!",
        
        # é«˜æ”»å‡»æ€§ (8ä¸ª)
        "You're such an idiot for writing this garbage!",
        "What a stupid fool, can't get anything right!",
        "You're a complete moron and total loser!",
        "This author is clearly a brainless imbecile!",
        "You're pathetic and your work is trash!",
        "What a worthless piece of human garbage!",
        "You're too stupid to understand anything!",
        "Get a brain, you mindless piece of shit!"
    ]
    
    # é«˜æ•ˆå˜ä½“ç”Ÿæˆå™¨
    efficient_variations = [
        "", " Really!", " Seriously.", " Just saying.", " Obviously.",
        " Come on!", " Period.", " That's the truth.", " Absolutely.",
        " For sure.", " Definitely.", " Completely.", " Totally."
    ]
    
    efficient_prefixes = [
        "", "Look, ", "Listen, ", "Honestly, ", "Frankly, ",
        "Let me tell you, ", "The fact is, ", "Bottom line: ",
        "Real talk: ", "I have to say, "
    ]
    
    # ç”Ÿæˆ5000ä¸ªæ ·æœ¬ (æ¯ä¸ªæ¨¡æ¿çº¦167ä¸ªå˜ä½“)
    comments = []
    labels_data = {
        'toxic': [], 'severe_toxic': [], 'obscene': [],
        'threat': [], 'insult': [], 'identity_hate': []
    }
    
    samples_per_template = 167
    
    for i, template in enumerate(base_templates):
        for j in range(samples_per_template):
            # éšæœºç»„åˆ
            prefix = random.choice(efficient_prefixes)
            suffix = random.choice(efficient_variations)
            comment = prefix + template + suffix
            
            # æ·»åŠ å˜åŒ–
            if j % 4 == 0:
                comment = comment.replace("!", "!!!")
            elif j % 4 == 1:
                comment = comment.upper()
            elif j % 4 == 2:
                comment = comment.replace(" ", "  ")  # åŒç©ºæ ¼
            
            comments.append(comment)
            
            # é«˜æ•ˆæ ‡ç­¾åˆ†é…
            comment_type = i // 8  # 0:æ­£å¸¸, 1:è½»åº¦è´Ÿé¢, 2:ä¸­åº¦æ”»å‡», 3:é«˜æ”»å‡»
            comment_lower = comment.lower()
            
            # Toxic
            toxic = 1 if (comment_type >= 2 or any(word in comment_lower for word in ['stupid', 'idiot', 'moron', 'garbage', 'shit'])) else 0
            labels_data['toxic'].append(toxic)
            
            # Severe toxic
            severe_toxic = 1 if (comment_type >= 3 and any(word in comment_lower for word in ['shit', 'garbage', 'trash'])) else 0
            labels_data['severe_toxic'].append(severe_toxic)
            
            # Obscene
            obscene = 1 if any(word in comment_lower for word in ['shit', 'damn']) else 0
            labels_data['obscene'].append(obscene)
            
            # Threat
            threat = 1 if (comment_type >= 3 and j % 10 == 0) else 0  # å°‘é‡å¨èƒ
            labels_data['threat'].append(threat)
            
            # Insult
            insult = 1 if (comment_type >= 3 or any(word in comment_lower for word in ['idiot', 'moron', 'stupid', 'fool', 'loser'])) else 0
            labels_data['insult'].append(insult)
            
            # Identity hate
            identity_hate = 1 if (comment_type >= 3 and j % 15 == 0) else 0  # å°‘é‡èº«ä»½ä»‡æ¨
            labels_data['identity_hate'].append(identity_hate)
    
    # ç¡®ä¿æ­£å¥½5000ä¸ªæ ·æœ¬
    comments = comments[:5000]
    for key in labels_data:
        labels_data[key] = labels_data[key][:5000]
    
    data = {
        'id': range(5000),
        'comment_text': comments,
        **labels_data
    }
    
    df = pd.DataFrame(data)
    print(f"âœ… ç”Ÿæˆäº† {len(df)} ä¸ªé«˜è´¨é‡è®­ç»ƒæ ·æœ¬")
    return df

def create_efficient_test_dataset():
    """åˆ›å»º400ä¸ªå¤šæ ·åŒ–æµ‹è¯•æ ·æœ¬"""
    test_templates = [
        "This is wonderful work!", "I completely disagree here.", "Could you explain more?", "This makes no sense.",
        "Brilliant analysis!", "Total garbage content.", "You're absolutely right.", "This is confusing.",
        "Excellent research!", "Pretty disappointing.", "Very helpful, thanks!", "I'm not convinced.",
        "Outstanding work!", "Seems questionable.", "Perfect explanation!", "Rather unconvincing.",
        "Truly impressive!", "Somewhat problematic.", "Great job overall!", "Definitely needs work."
    ]
    
    test_comments = []
    for template in test_templates:
        for i in range(20):  # æ¯ä¸ªæ¨¡æ¿20ä¸ªå˜ä½“
            if i % 4 == 0:
                comment = template + " Really impressive stuff."
            elif i % 4 == 1:
                comment = "Honestly, " + template.lower()
            elif i % 4 == 2:
                comment = template + " What are your thoughts?"
            else:
                comment = template
            test_comments.append(comment)
    
    return pd.DataFrame({
        'id': range(20000, 20000 + len(test_comments)),
        'comment_text': test_comments
    })

# ==================== ç²¾é€‰æ ¸å¿ƒç‰¹å¾ ====================

def extract_core_features(df):
    """æå–15ç»´æ ¸å¿ƒç‰¹å¾"""
    print("ğŸ”§ æå–15ç»´æ ¸å¿ƒç‰¹å¾...")
    
    features = pd.DataFrame()
    text_col = df['comment_text']
    
    # 1-5: åŸºç¡€ç»Ÿè®¡
    features['text_length'] = text_col.str.len()
    features['word_count'] = text_col.str.split().str.len()
    features['sentence_count'] = text_col.str.count(r'[.!?]') + 1
    features['caps_count'] = text_col.str.count(r'[A-Z]')
    features['caps_ratio'] = features['caps_count'] / (features['text_length'] + 1)
    
    # 6-10: æ ‡ç‚¹å’Œç‰¹æ®Šå­—ç¬¦
    features['exclamation_count'] = text_col.str.count('!')
    features['question_count'] = text_col.str.count('\?')
    features['digit_count'] = text_col.str.count(r'\d')
    features['special_char_count'] = text_col.str.count(r'[^a-zA-Z0-9\s]')
    features['punctuation_ratio'] = features['special_char_count'] / (features['text_length'] + 1)
    
    # 11-13: è¯æ±‡ç‰¹å¾
    def unique_word_ratio(text):
        if pd.isna(text) or len(str(text).split()) == 0:
            return 0
        words = str(text).split()
        return len(set(words)) / len(words)
    
    features['unique_word_ratio'] = text_col.apply(unique_word_ratio)
    features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1)
    features['avg_sentence_length'] = features['word_count'] / (features['sentence_count'] + 1)
    
    # 14-15: é«˜çº§ç‰¹å¾
    def repeated_char_ratio(text):
        if pd.isna(text) or len(str(text)) <= 1:
            return 0
        text = str(text)
        repeated = sum(1 for i in range(1, len(text)) if text[i] == text[i-1])
        return repeated / len(text)
    
    features['repeated_char_ratio'] = text_col.apply(repeated_char_ratio)
    
    def caps_word_ratio(text):
        if pd.isna(text):
            return 0
        words = str(text).split()
        if len(words) == 0:
            return 0
        caps_words = sum(1 for word in words if word.isupper())
        return caps_words / len(words)
    
    features['caps_word_ratio'] = text_col.apply(caps_word_ratio)
    
    features = features.fillna(0)
    print(f"âœ… æå–äº† {features.shape[1]} ç»´æ ¸å¿ƒç‰¹å¾")
    return features

# ==================== å¿«é€Ÿæ–‡æœ¬é¢„å¤„ç† ====================

def turbo_text_preprocessing(text):
    """æé€Ÿæ–‡æœ¬é¢„å¤„ç†"""
    if pd.isna(text):
        return ""
    
    text = str(text)
    
    # ä¿å­˜é‡è¦ä¿¡æ¯
    text = re.sub(r'[!]{2,}', ' MULTIPLE_EXCLAMATION ', text)
    text = re.sub(r'[?]{2,}', ' MULTIPLE_QUESTION ', text)
    text = re.sub(r'[A-Z]{3,}', ' SCREAMING ', text)
    
    # å¿«é€Ÿæ ‡å‡†åŒ–
    text = text.lower()
    text = re.sub(r"won't", "will not", text)
    text = re.sub(r"can't", "cannot", text)
    text = re.sub(r"n't", " not", text)
    text = re.sub(r'(.)\1{3,}', r'\1\1', text)  # é‡å¤å­—ç¬¦
    text = re.sub(r'http\S+', ' URL ', text)
    text = re.sub(r'\d+', ' NUMBER ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

# ==================== å¿«é€Ÿæ•°æ®å¢å¼º ====================

def quick_data_augmentation(df, ratio=0.1):
    """å¿«é€Ÿæ•°æ®å¢å¼º"""
    print(f"âš¡ å¿«é€Ÿæ•°æ®å¢å¼ºï¼Œæ¯”ä¾‹: {ratio}")
    
    toxic_samples = df[df['toxic'] == 1].sample(n=min(500, len(df[df['toxic'] == 1])))
    
    augmented = []
    target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
    
    for idx, row in toxic_samples.iterrows():
        if random.random() < ratio:
            # ç®€å•å˜æ¢
            text = row['comment_text']
            
            # éšæœºé€‰æ‹©å˜æ¢
            if random.random() < 0.3:
                text = text.replace(" ", "  ")  # åŒç©ºæ ¼
            elif random.random() < 0.3:
                text = text.replace("!", "!!!")  # å¤šæ„Ÿå¹å·
            else:
                text = text + " Really!"  # æ·»åŠ åç¼€
            
            new_sample = {'id': len(df) + len(augmented), 'comment_text': text}
            for col in target_cols:
                new_sample[col] = row[col]
            augmented.append(new_sample)
    
    if augmented:
        augmented_df = pd.DataFrame(augmented)
        df = pd.concat([df, augmented_df], ignore_index=True)
        print(f"âœ… å¢å¼ºäº† {len(augmented)} ä¸ªæ ·æœ¬")
    
    return df

# ==================== å¿«é€Ÿé›†æˆæ¨¡å‹ ====================

def create_turbo_ensemble():
    """åˆ›å»º3ä¸ªå¿«é€Ÿæ¨¡å‹"""
    return {
        'logistic': LogisticRegression(C=2, solver='liblinear', random_state=42, max_iter=500),
        'random_forest': RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1, max_depth=10),
        'naive_bayes': MultinomialNB(alpha=0.1)
    }

def train_turbo_ensemble(X_train, y_train, target_columns):
    """è®­ç»ƒå¿«é€Ÿé›†æˆæ¨¡å‹"""
    print("âš¡ è®­ç»ƒå¿«é€Ÿé›†æˆæ¨¡å‹...")
    
    base_models = create_turbo_ensemble()
    ensemble_models = {}
    
    for i, col in enumerate(target_columns):
        print(f"  è®­ç»ƒ {col}...")
        
        y_col = y_train[:, i]
        
        if len(np.unique(y_col)) < 2:
            continue
        
        # å¿«é€Ÿç±»åˆ«æƒé‡
        try:
            class_weights = compute_class_weight('balanced', classes=np.unique(y_col), y=y_col)
            class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_col), class_weights)}
        except:
            class_weight_dict = 'balanced'
        
        col_models = {}
        for name, model in base_models.items():
            try:
                if name in ['logistic', 'random_forest']:
                    model.set_params(class_weight=class_weight_dict)
                
                model.fit(X_train, y_col)
                col_models[name] = model
                
            except Exception as e:
                print(f"    {name} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        ensemble_models[col] = col_models
    
    return ensemble_models

def predict_turbo_ensemble(ensemble_models, X_test, target_columns):
    """å¿«é€Ÿé›†æˆé¢„æµ‹"""
    predictions = {}
    
    for col in target_columns:
        if col not in ensemble_models:
            predictions[col] = np.zeros(X_test.shape[0])
            continue
        
        col_predictions = []
        for name, model in ensemble_models[col].items():
            try:
                pred_proba = model.predict_proba(X_test)
                if pred_proba.shape[1] == 2:
                    col_predictions.append(pred_proba[:, 1])
                else:
                    col_predictions.append(pred_proba[:, 0])
            except:
                continue
        
        if col_predictions:
            ensemble_pred = np.mean(col_predictions, axis=0)
            predictions[col] = ensemble_pred
        else:
            predictions[col] = np.zeros(X_test.shape[0])
    
    return predictions

# ==================== ä¸»å‡½æ•° ====================

def main_turbo_optimized():
    """æé€Ÿä¼˜åŒ–ä¸»å‡½æ•°"""
    print("="*80)
    print("âš¡ Jigsaw æé€Ÿä¼˜åŒ–ç‰ˆæœ¬")
    print("ç›®æ ‡ï¼š20%+ é¢„æµ‹å¤šæ ·æ€§ï¼Œå¿«é€Ÿè®­ç»ƒ")
    print("="*80)
    
    # 1. é«˜æ•ˆæ•°æ®ç”Ÿæˆ
    train_df = create_efficient_diverse_dataset()
    test_df = create_efficient_test_dataset()
    
    target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
    
    # æ ‡ç­¾åˆ†å¸ƒ
    print("\nğŸ“Š æ•°æ®é›†æ ‡ç­¾åˆ†å¸ƒ:")
    for col in target_columns:
        count = train_df[col].sum()
        ratio = count / len(train_df) * 100
        print(f"  {col}: {count:,} ({ratio:.1f}%)")
    
    # 2. å¿«é€Ÿæ•°æ®å¢å¼º
    train_df = quick_data_augmentation(train_df, ratio=0.1)
    print(f"å¢å¼ºåæ€»æ ·æœ¬æ•°: {len(train_df):,}")
    
    # 3. å¿«é€Ÿæ–‡æœ¬é¢„å¤„ç†
    print("\nğŸ”§ å¿«é€Ÿæ–‡æœ¬é¢„å¤„ç†...")
    train_df['comment_text_clean'] = train_df['comment_text'].apply(turbo_text_preprocessing)
    test_df['comment_text_clean'] = test_df['comment_text'].apply(turbo_text_preprocessing)
    
    # 4. æå–æ ¸å¿ƒç‰¹å¾
    train_core_features = extract_core_features(train_df)
    test_core_features = extract_core_features(test_df)
    
    # 5. é«˜æ•ˆæ–‡æœ¬ç‰¹å¾
    print("\nğŸ¯ æå–æ–‡æœ¬ç‰¹å¾...")
    
    # è¯çº§ TF-IDF
    tfidf_word = TfidfVectorizer(
        max_features=5000,
        ngram_range=(1, 2),
        stop_words='english',
        min_df=2,
        max_df=0.95
    )
    
    X_train_tfidf = tfidf_word.fit_transform(train_df['comment_text_clean'])
    X_test_tfidf = tfidf_word.transform(test_df['comment_text_clean'])
    
    # å­—ç¬¦çº§ TF-IDF
    tfidf_char = TfidfVectorizer(
        max_features=2000,
        ngram_range=(3, 4),
        analyzer='char_wb'
    )
    
    X_train_char = tfidf_char.fit_transform(train_df['comment_text_clean'])
    X_test_char = tfidf_char.transform(test_df['comment_text_clean'])
    
    # æ ‡å‡†åŒ–æ ¸å¿ƒç‰¹å¾
    scaler = StandardScaler()
    X_train_core_scaled = scaler.fit_transform(train_core_features)
    X_test_core_scaled = scaler.transform(test_core_features)
    
    # ç»„åˆç‰¹å¾
    X_train_combined = hstack([
        X_train_tfidf,
        X_train_char,
        csr_matrix(X_train_core_scaled)
    ])
    
    X_test_combined = hstack([
        X_test_tfidf,
        X_test_char,
        csr_matrix(X_test_core_scaled)
    ])
    
    print(f"âš¡ ç»„åˆç‰¹å¾å½¢çŠ¶: {X_train_combined.shape}")
    
    # 6. å¿«é€Ÿåˆ†å‰²æ•°æ®
    y = train_df[target_columns].values
    test_ids = test_df['id'].values
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_combined, y, test_size=0.2, random_state=42, stratify=y[:, 0]
    )
    
    # 7. è®­ç»ƒå¿«é€Ÿé›†æˆ
    ensemble_models = train_turbo_ensemble(X_train, y_train, target_columns)
    
    # 8. éªŒè¯æ€§èƒ½
    print("\nğŸ“ˆ éªŒè¯é›†æ€§èƒ½:")
    val_predictions = predict_turbo_ensemble(ensemble_models, X_val, target_columns)
    
    auc_scores = []
    for i, col in enumerate(target_columns):
        if len(np.unique(y_val[:, i])) > 1:
            auc = roc_auc_score(y_val[:, i], val_predictions[col])
            auc_scores.append(auc)
            print(f"  {col}: AUC = {auc:.4f}")
        else:
            auc_scores.append(0.5)
            print(f"  {col}: N/A (å•ä¸€ç±»åˆ«)")
    
    print(f"  å¹³å‡ AUC: {np.mean(auc_scores):.4f}")
    
    # 9. æµ‹è¯•é›†é¢„æµ‹
    print("\nğŸ¯ æµ‹è¯•é›†é¢„æµ‹...")
    test_predictions = predict_turbo_ensemble(ensemble_models, X_test_combined, target_columns)
    
    # 10. åˆ›å»ºæäº¤æ–‡ä»¶
    submission = pd.DataFrame({'id': test_ids})
    for col in target_columns:
        submission[col] = test_predictions[col]
    
    submission.to_csv('submission_turbo_optimized.csv', index=False)
    
    # 11. è¯¦ç»†åˆ†æ
    print("\n" + "="*80)
    print("âš¡ æé€Ÿä¼˜åŒ–å®Œæˆï¼")
    print("="*80)
    
    print("\nğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
    for col in target_columns:
        pred = test_predictions[col]
        print(f"  {col}: å¹³å‡={pred.mean():.4f}, æ ‡å‡†å·®={pred.std():.4f}, èŒƒå›´=[{pred.min():.4f}, {pred.max():.4f}]")
    
    # å¤šæ ·æ€§åˆ†æ
    print(f"\nğŸ¯ é¢„æµ‹å¤šæ ·æ€§åˆ†æ:")
    unique_predictions = len(set(tuple(np.round(submission.iloc[i, 1:].values, 4)) for i in range(len(submission))))
    diversity_ratio = unique_predictions / len(submission) * 100
    
    print(f"  ä¸åŒé¢„æµ‹ç»„åˆæ•°: {unique_predictions:,} / {len(submission):,}")
    print(f"  é¢„æµ‹å¤šæ ·æ€§: {diversity_ratio:.1f}%")
    
    if diversity_ratio > 20:
        print(f"  ğŸ‰ æˆåŠŸï¼é¢„æµ‹å¤šæ ·æ€§ {diversity_ratio:.1f}% > 20%")
    else:
        print(f"  âš ï¸  è¿˜éœ€ä¼˜åŒ–ï¼Œå½“å‰ {diversity_ratio:.1f}% < 20%")
    
    # é¢„æµ‹åˆ†å¸ƒ
    print(f"\nğŸ“ˆ é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ:")
    for col in target_columns:
        pred = test_predictions[col]
        low = (pred < 0.1).sum()
        mid = ((pred >= 0.1) & (pred < 0.5)).sum()
        high = (pred >= 0.5).sum()
        print(f"  {col}: ä½(<0.1)={low}, ä¸­(0.1-0.5)={mid}, é«˜(>=0.5)={high}")
    
    return submission, ensemble_models, diversity_ratio

if __name__ == "__main__":
    submission, models, diversity = main_turbo_optimized()
    
    print(f"\nğŸ¯ æœ€ç»ˆç»“æœ: é¢„æµ‹å¤šæ ·æ€§ = {diversity:.1f}%")
    if diversity > 20:
        print("ğŸ‰ æé€Ÿä¼˜åŒ–æˆåŠŸï¼ç›®æ ‡è¾¾æˆï¼")
    else:
        print("âš ï¸ éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´å‚æ•°...") 