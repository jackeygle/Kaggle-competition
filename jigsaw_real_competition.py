#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jigsaw Agile Community Rules - çœŸå®æ¯”èµ›æ•°æ®è®­ç»ƒè„šæœ¬
ğŸ¯ ç›®æ ‡ï¼šåœ¨çœŸå®Kaggleæ¯”èµ›æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹

æ¯”èµ›ä¿¡æ¯ï¼š
- ä»»åŠ¡ï¼šäºŒåˆ†ç±»ï¼ˆé¢„æµ‹æ˜¯å¦è¿åç¤¾åŒºè§„åˆ™ï¼‰
- è®­ç»ƒæ•°æ®ï¼š2029ä¸ªæ ·æœ¬
- æµ‹è¯•æ•°æ®ï¼š67ä¸ªæ ·æœ¬
- ç‰¹å¾ï¼šbody(æ–‡æœ¬) + rule(è§„åˆ™) + subreddit(ç¤¾åŒº) + ç¤ºä¾‹
"""

import pandas as pd
import numpy as np
import re
import string
import random
import logging
import time
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy.sparse import hstack, csr_matrix
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­
np.random.seed(42)
random.seed(42)

# ==================== é…ç½® ====================

class Config:
    """è®­ç»ƒé…ç½®"""
    
    # ç›®æ ‡è®¾ç½®
    TARGET_AUC = 0.85  # çœŸå®æ•°æ®ä¸Šçš„åˆç†ç›®æ ‡
    MAX_OPTIMIZATION_ROUNDS = 5
    
    # æ¨¡å‹è®¾ç½®
    CV_FOLDS = 5
    RANDOM_STATE = 42
    
    # æ•°æ®è·¯å¾„
    TRAIN_PATH = './train.csv'
    TEST_PATH = './test.csv'
    OUTPUT_PATH = './'
    
    # æ ‡ç­¾åˆ—
    LABEL_COL = 'rule_violation'

# ==================== æ—¥å¿—è®¾ç½® ====================

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('real_competition_training.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

# ==================== æ–‡æœ¬é¢„å¤„ç† ====================

class RealDataPreprocessor:
    """çœŸå®æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def clean_text(self, text):
        """æ¸…ç†æ–‡æœ¬"""
        if pd.isna(text):
            return ""
        
        text = str(text)
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[^\w\s]', ' ', text)
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        # è½¬æ¢ä¸ºå°å†™
        text = text.lower().strip()
        
        return text
    
    def extract_features(self, df):
        """æå–ç‰¹å¾"""
        self.logger.info("ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹...")
        
        # 1. æ–‡æœ¬ç‰¹å¾
        body_texts = df['body'].apply(self.clean_text)
        rule_texts = df['rule'].apply(self.clean_text)
        
        # 2. TF-IDFç‰¹å¾
        body_tfidf = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            stop_words='english',
            min_df=2
        ).fit_transform(body_texts)
        
        rule_tfidf = TfidfVectorizer(
            max_features=500,
            ngram_range=(1, 2),
            stop_words='english',
            min_df=2
        ).fit_transform(rule_texts)
        
        # 3. ç»Ÿè®¡ç‰¹å¾
        body_length = df['body'].str.len().values.reshape(-1, 1)
        rule_length = df['rule'].str.len().values.reshape(-1, 1)
        word_count = df['body'].str.split().str.len().values.reshape(-1, 1)
        
        # 4. ç¤¾åŒºç‰¹å¾ï¼ˆOne-hotç¼–ç ï¼‰
        subreddit_encoder = LabelEncoder()
        subreddit_encoded = subreddit_encoder.fit_transform(df['subreddit'].fillna('unknown')).reshape(-1, 1)
        
        # 5. ç¤ºä¾‹ç‰¹å¾
        pos_example_1_len = df['positive_example_1'].str.len().fillna(0).values.reshape(-1, 1)
        pos_example_2_len = df['positive_example_2'].str.len().fillna(0).values.reshape(-1, 1)
        neg_example_1_len = df['negative_example_1'].str.len().fillna(0).values.reshape(-1, 1)
        neg_example_2_len = df['negative_example_2'].str.len().fillna(0).values.reshape(-1, 1)
        
        # 6. æ–‡æœ¬ç›¸ä¼¼åº¦ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        body_rule_similarity = np.array([
            len(set(body.split()) & set(rule.split())) / max(len(set(body.split()) | set(rule.split())), 1)
            for body, rule in zip(body_texts, rule_texts)
        ]).reshape(-1, 1)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        statistical_features = np.hstack([
            body_length, rule_length, word_count,
            subreddit_encoded,
            pos_example_1_len, pos_example_2_len,
            neg_example_1_len, neg_example_2_len,
            body_rule_similarity
        ])
        
        # æ ‡å‡†åŒ–ç»Ÿè®¡ç‰¹å¾
        scaler = StandardScaler()
        statistical_features = scaler.fit_transform(statistical_features)
        
        # åˆå¹¶TF-IDFå’Œç»Ÿè®¡ç‰¹å¾
        final_features = hstack([body_tfidf, rule_tfidf, statistical_features])
        
        # è½¬æ¢ä¸ºCSRæ ¼å¼ä»¥ä¾¿åˆ‡ç‰‡
        final_features = final_features.tocsr()
        
        self.logger.info(f"ğŸ‰ ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæœ€ç»ˆç»´åº¦: {final_features.shape}")
        
        return final_features

# ==================== æ¨¡å‹è®­ç»ƒå™¨ ====================

class RealCompetitionTrainer:
    """çœŸå®æ¯”èµ›è®­ç»ƒå™¨"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.preprocessor = RealDataPreprocessor()
        
        # å®šä¹‰æ¨¡å‹
        self.models = {
            'LogisticRegression_L1': LogisticRegression(
                C=1.0, penalty='l1', solver='liblinear', random_state=42
            ),
            'LogisticRegression_L2': LogisticRegression(
                C=1.0, penalty='l2', random_state=42
            ),
            'RandomForest': RandomForestClassifier(
                n_estimators=200, max_depth=10, random_state=42
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=150, learning_rate=0.1, max_depth=6, random_state=42
            ),
            'MultinomialNB': MultinomialNB(alpha=0.1)
        }
        
        # æ¨¡å‹æƒé‡
        self.model_weights = {
            'LogisticRegression_L1': 0.2,
            'LogisticRegression_L2': 0.2,
            'RandomForest': 0.25,
            'GradientBoosting': 0.25,
            'MultinomialNB': 0.1
        }
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        self.logger.info("ğŸ“‚ åŠ è½½çœŸå®æ¯”èµ›æ•°æ®...")
        
        train_df = pd.read_csv(self.config.TRAIN_PATH)
        test_df = pd.read_csv(self.config.TEST_PATH)
        
        self.logger.info(f"âœ… è®­ç»ƒæ•°æ®: {train_df.shape}")
        self.logger.info(f"âœ… æµ‹è¯•æ•°æ®: {test_df.shape}")
        self.logger.info(f"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {train_df[self.config.LABEL_COL].value_counts().to_dict()}")
        
        return train_df, test_df
    
    def prepare_features(self, train_df, test_df):
        """å‡†å¤‡ç‰¹å¾"""
        self.logger.info("ğŸ”§ å‡†å¤‡ç‰¹å¾...")
        
        # åˆå¹¶æ•°æ®ä»¥ä¿æŒç‰¹å¾ä¸€è‡´æ€§
        combined_df = pd.concat([train_df, test_df], ignore_index=True)
        
        # æå–ç‰¹å¾
        features = self.preprocessor.extract_features(combined_df)
        
        # åˆ†ç¦»è®­ç»ƒå’Œæµ‹è¯•ç‰¹å¾
        train_features = features[:len(train_df), :]
        test_features = features[len(train_df):, :]
        
        return train_features, test_features, train_df[self.config.LABEL_COL]
    
    def train_models(self, X_train, y_train, X_val, y_val):
        """è®­ç»ƒæ¨¡å‹"""
        model_results = {}
        predictions = []
        
        for name, model in self.models.items():
            self.logger.info(f"  ğŸš€ è®­ç»ƒ {name}...")
            
            try:
                # æœ´ç´ è´å¶æ–¯éœ€è¦éè´Ÿç‰¹å¾
                if name == 'MultinomialNB':
                    X_train_nb = np.abs(X_train.toarray() if hasattr(X_train, 'toarray') else X_train)
                    X_val_nb = np.abs(X_val.toarray() if hasattr(X_val, 'toarray') else X_val)
                    model.fit(X_train_nb, y_train)
                    pred = model.predict_proba(X_val_nb)[:, 1]
                else:
                    model.fit(X_train, y_train)
                    pred = model.predict_proba(X_val)[:, 1]
                
                auc = roc_auc_score(y_val, pred)
                model_results[name] = auc
                predictions.append(pred)
                
                self.logger.info(f"    âœ… {name}: {auc:.4f}")
                
            except Exception as e:
                self.logger.error(f"    âŒ {name} è®­ç»ƒå¤±è´¥: {e}")
                model_results[name] = 0.5
                predictions.append(np.random.random(len(y_val)))
        
        return model_results, predictions
    
    def ensemble_predict(self, model_results, predictions, y_val):
        """é›†æˆé¢„æµ‹"""
        # åŠ æƒå¹³å‡
        weighted_pred = np.zeros(len(y_val))
        total_weight = 0
        
        for i, (name, auc) in enumerate(model_results.items()):
            weight = self.model_weights[name] * auc  # æ ¹æ®AUCè°ƒæ•´æƒé‡
            weighted_pred += predictions[i] * weight
            total_weight += weight
        
        if total_weight > 0:
            weighted_pred /= total_weight
        
        ensemble_auc = roc_auc_score(y_val, weighted_pred)
        
        return ensemble_auc, weighted_pred
    
    def cross_validation(self, X, y):
        """äº¤å‰éªŒè¯"""
        self.logger.info("ğŸ”„ å¼€å§‹äº¤å‰éªŒè¯...")
        
        skf = StratifiedKFold(n_splits=self.config.CV_FOLDS, shuffle=True, random_state=42)
        fold_results = []
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
            self.logger.info(f"  ğŸ“Š æŠ˜ {fold}/{self.config.CV_FOLDS}")
            
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            # è®­ç»ƒæ¨¡å‹
            model_results, predictions = self.train_models(X_train, y_train, X_val, y_val)
            
            # é›†æˆé¢„æµ‹
            ensemble_auc, ensemble_pred = self.ensemble_predict(model_results, predictions, y_val)
            
            fold_results.append({
                'fold': fold,
                'ensemble_auc': ensemble_auc,
                'model_results': model_results
            })
            
            self.logger.info(f"    ğŸ¯ é›†æˆAUC: {ensemble_auc:.4f}")
        
        # è®¡ç®—å¹³å‡ç»“æœ
        avg_auc = np.mean([r['ensemble_auc'] for r in fold_results])
        std_auc = np.std([r['ensemble_auc'] for r in fold_results])
        
        self.logger.info(f"ğŸ“ˆ äº¤å‰éªŒè¯ç»“æœ: {avg_auc:.4f} Â± {std_auc:.4f}")
        
        return avg_auc, fold_results
    
    def train_final_model(self, X_train, y_train, X_test):
        """è®­ç»ƒæœ€ç»ˆæ¨¡å‹"""
        self.logger.info("ğŸ† è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
        
        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        final_models = {}
        test_predictions = []
        
        for name, model in self.models.items():
            self.logger.info(f"  ğŸš€ è®­ç»ƒæœ€ç»ˆ {name}...")
            
            try:
                if name == 'MultinomialNB':
                    X_train_nb = np.abs(X_train.toarray() if hasattr(X_train, 'toarray') else X_train)
                    X_test_nb = np.abs(X_test.toarray() if hasattr(X_test, 'toarray') else X_test)
                    model.fit(X_train_nb, y_train)
                    pred = model.predict_proba(X_test_nb)[:, 1]
                else:
                    model.fit(X_train, y_train)
                    pred = model.predict_proba(X_test)[:, 1]
                
                final_models[name] = model
                test_predictions.append(pred)
                
            except Exception as e:
                self.logger.error(f"    âŒ {name} è®­ç»ƒå¤±è´¥: {e}")
                test_predictions.append(np.random.random(X_test.shape[0]))
        
        # é›†æˆé¢„æµ‹
        final_pred = np.zeros(X_test.shape[0])
        total_weight = 0
        
        for i, name in enumerate(self.models.keys()):
            weight = self.model_weights[name]
            final_pred += test_predictions[i] * weight
            total_weight += weight
        
        if total_weight > 0:
            final_pred /= total_weight
        
        return final_pred
    
    def generate_submission(self, predictions, test_df):
        """ç”Ÿæˆæäº¤æ–‡ä»¶"""
        self.logger.info("ğŸ“ ç”Ÿæˆæäº¤æ–‡ä»¶...")
        
        submission_df = pd.DataFrame({
            'row_id': test_df['row_id'],
            'rule_violation': predictions
        })
        
        submission_path = f"{self.config.OUTPUT_PATH}submission_real_competition.csv"
        submission_df.to_csv(submission_path, index=False)
        
        self.logger.info(f"âœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {submission_path}")
        self.logger.info(f"ğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
        self.logger.info(f"  å‡å€¼: {predictions.mean():.4f}")
        self.logger.info(f"  æ ‡å‡†å·®: {predictions.std():.4f}")
        self.logger.info(f"  èŒƒå›´: [{predictions.min():.4f}, {predictions.max():.4f}]")
        
        return submission_path
    
    def train(self):
        """ä¸»è®­ç»ƒæµç¨‹"""
        start_time = time.time()
        
        self.logger.info("ğŸš€ å¼€å§‹çœŸå®æ¯”èµ›è®­ç»ƒæµç¨‹...")
        
        # 1. åŠ è½½æ•°æ®
        train_df, test_df = self.load_data()
        
        # 2. å‡†å¤‡ç‰¹å¾
        X_train, X_test, y_train = self.prepare_features(train_df, test_df)
        
        # 3. äº¤å‰éªŒè¯
        cv_auc, fold_results = self.cross_validation(X_train, y_train)
        
        # 4. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        if cv_auc >= self.config.TARGET_AUC:
            self.logger.info(f"ğŸ‰ ç›®æ ‡è¾¾æˆï¼AUC {cv_auc:.4f} >= {self.config.TARGET_AUC}")
        else:
            self.logger.info(f"âš ï¸ æœªè¾¾åˆ°ç›®æ ‡ï¼Œå½“å‰AUC {cv_auc:.4f} < {self.config.TARGET_AUC}")
        
        # 5. è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        final_predictions = self.train_final_model(X_train, y_train, X_test)
        
        # 6. ç”Ÿæˆæäº¤æ–‡ä»¶
        submission_path = self.generate_submission(final_predictions, test_df)
        
        # 7. ç”ŸæˆæŠ¥å‘Š
        end_time = time.time()
        self.generate_report(cv_auc, fold_results, start_time, end_time, submission_path)
        
        return cv_auc, submission_path
    
    def generate_report(self, final_auc, fold_results, start_time, end_time, submission_path):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        training_time = end_time - start_time
        
        self.logger.info("\n" + "="*80)
        self.logger.info("ğŸ† çœŸå®æ¯”èµ›è®­ç»ƒå®ŒæˆæŠ¥å‘Š")
        self.logger.info("="*80)
        self.logger.info(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
        self.logger.info(f"ğŸ¯ æœ€ç»ˆAUC: {final_auc:.4f}")
        self.logger.info(f"ğŸ“Š ç›®æ ‡AUC: {self.config.TARGET_AUC}")
        self.logger.info(f"âœ… ç›®æ ‡è¾¾æˆ: {'æ˜¯' if final_auc >= self.config.TARGET_AUC else 'å¦'}")
        self.logger.info(f"ğŸ“ æäº¤æ–‡ä»¶: {submission_path}")
        
        self.logger.info("\nğŸ“ˆ å„æŠ˜è¯¦ç»†ç»“æœ:")
        for result in fold_results:
            self.logger.info(f"  æŠ˜ {result['fold']}: {result['ensemble_auc']:.4f}")
        
        self.logger.info("\nğŸ‰ğŸ‰ğŸ‰ è®­ç»ƒå®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰")

# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸš€ Jigsaw Agile Community Rules - çœŸå®æ¯”èµ›è®­ç»ƒè„šæœ¬")
    print("ğŸ¯ ç›®æ ‡ï¼šåœ¨çœŸå®Kaggleæ¯”èµ›æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹")
    print("="*80)
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    # åˆ›å»ºé…ç½®
    config = Config()
    
    # è®°å½•ç¯å¢ƒä¿¡æ¯
    logger.info(f"ğŸ Pythonç‰ˆæœ¬: {pd.__version__}")
    logger.info(f"ğŸ“¦ Pandasç‰ˆæœ¬: {pd.__version__}")
    logger.info(f"ğŸ¯ ç›®æ ‡AUC: {config.TARGET_AUC}")
    logger.info(f"ğŸ”„ äº¤å‰éªŒè¯æŠ˜æ•°: {config.CV_FOLDS}")
    logger.info(f"ğŸ“‚ è®­ç»ƒæ•°æ®è·¯å¾„: {config.TRAIN_PATH}")
    logger.info(f"ğŸ“‚ æµ‹è¯•æ•°æ®è·¯å¾„: {config.TEST_PATH}")
    logger.info(f"ğŸš€ å¯åŠ¨è®­ç»ƒæµç¨‹...")
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = RealCompetitionTrainer(config)
        
        # å¼€å§‹è®­ç»ƒ
        final_auc, submission_path = trainer.train()
        
        print(f"\nğŸ‰ğŸ‰ğŸ‰ è®­ç»ƒæˆåŠŸï¼æœ€ç»ˆAUC: {final_auc:.4f} ğŸ‰ğŸ‰ğŸ‰")
        print(f"ğŸ“ æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {submission_path}")
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main() 